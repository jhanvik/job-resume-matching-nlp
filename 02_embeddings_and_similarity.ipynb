{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693a1183-2e24-4838-bed7-ae575d86d950",
   "metadata": {},
   "source": [
    "### To get an end to end pipeling working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b84b0500-c574-4449-9fdd-58832c93365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re  ##regex library (used in cleaning + skill extraction)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   ##converts text into numeric vectors (TF-IDF).\n",
    "from sklearn.metrics.pairwise import cosine_similarity  ##compares vectors and returns similarity scores from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e78d1170-5af8-4ef8-8ca2-c105b4e25677",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(r\"C:\\Users\\jhanvi.kasundra\\Downloads\\Projects New\\Data/jobs_clean.csv\")\n",
    "resumes = pd.read_csv(r\"C:\\Users\\jhanvi.kasundra\\Downloads\\Projects New\\Data/resumes_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cd1d1802-4a5f-4688-b670-2ca890c4eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stable IDs (super important for later Streamlit + Kafka)\n",
    "jobs = jobs.reset_index(drop=True)\n",
    "jobs[\"job_id\"] = jobs.index\n",
    "\n",
    "resumes = resumes.reset_index(drop=True)\n",
    "resumes[\"resume_id\"] = resumes.index\n",
    "\n",
    "##After filtering, sampling, dropping duplicates, etc., row numbers change.\n",
    "## having job id and resume id means you can always track whihc row matched later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4866e573-ad89-464f-b217-d8c6df9ed785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 2 — Text cleaning (spaces + HTML cleanup)\n",
    "# ============================================================\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)      # remove HTML tags\n",
    "    s = s.replace(\"&amp;\", \"&\")         # decode common HTML entity\n",
    "    s = re.sub(r\"\\s+\", \" \", s)          # collapse all whitespace (removes extra spaces/newlines)\n",
    "    return s.strip()\n",
    "\n",
    "jobs[\"job_title\"] = jobs[\"job_title\"].fillna(\"\").apply(clean_text)\n",
    "jobs[\"job_text\"]  = jobs[\"job_text\"].fillna(\"\").apply(clean_text)\n",
    "\n",
    "resumes[\"text_cv\"] = resumes[\"text_cv\"].fillna(\"\").apply(clean_text)\n",
    "resumes[\"category\"] = resumes[\"category\"].fillna(\"unknown\").str.lower().str.strip()\n",
    "\n",
    "## converts to strings safe even if NaN, removes basic html tags like <br>,<p>,etc\n",
    "## convert &amp; --> &\n",
    "## colapses multiple spaces/newlines into single space \n",
    "##trims ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a09d278-c517-48c2-9cf8-34b550e66345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "jobs: (13510, 6) | resumes: (12353, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove very short/noisy text + duplicates\n",
    "jobs = jobs.drop_duplicates(subset=[\"job_title\", \"job_text\"]).copy()\n",
    "jobs = jobs[jobs[\"job_text\"].str.len() >= 200].copy()\n",
    "\n",
    "resumes = resumes.drop_duplicates(subset=[\"category\", \"text_cv\"]).copy()\n",
    "resumes = resumes[resumes[\"text_cv\"].str.len() >= 200].copy()\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"jobs:\", jobs.shape, \"| resumes:\", resumes.shape)\n",
    "## removes duplicate job posts or duplicate resumes inflate results and shlow down compute\n",
    "## very short text like apply is useless for matching and creates ab dvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "380ab02f-092f-40f0-a9b4-938d620d87fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs after EXCLUDE_TITLES: (13220, 6) | removed: 290\n",
      "Jobs after ACADEMIC_EXCLUDE: (13160, 6) | removed: 60\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 3 — Global title exclusions (removes junk roles)\n",
    "# ============================================================\n",
    "EXCLUDE_TITLES = [\n",
    "    \"data entry\", \"data-entry\", \"entry specialist\", \"data entry assistant\",\n",
    "    \"logistics\", \"warehouse\", \"driver\",\n",
    "    \"facilities\", \"facility\",\n",
    "    \"cashier\", \"crew member\", \"barista\",\n",
    "    \"car wash\", \"delivery station\",\n",
    "    \"food service\", \"cook\", \"server\", \"dishwasher\",\n",
    "    \"security guard\", \"janitor\", \"maintenance\",\n",
    "]\n",
    "\n",
    "exclude_pattern = \"|\".join([re.escape(x) for x in EXCLUDE_TITLES])\n",
    "\n",
    "before = len(jobs)\n",
    "jobs = jobs[~jobs[\"job_title\"].str.lower().str.contains(exclude_pattern, na=False)].copy()\n",
    "print(f\"Jobs after EXCLUDE_TITLES: {jobs.shape} | removed: {before - len(jobs)}\")\n",
    "\n",
    "# Remove academia globally to prevent professor/faculty matches\n",
    "ACADEMIC_EXCLUDE = r\"(?:professor|faculty|lecturer|tenure|university|college|postdoc)\"\n",
    "before = len(jobs)\n",
    "jobs = jobs[~jobs[\"job_title\"].str.lower().str.contains(ACADEMIC_EXCLUDE, regex=True, na=False)].copy()\n",
    "print(f\"Jobs after ACADEMIC_EXCLUDE: {jobs.shape} | removed: {before - len(jobs)}\")\n",
    "\n",
    "## removes roles you dont want in that bucket (cashier/warehouse/etc)\n",
    "## makes your final recommendations much more relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c0f5887-5c11-4aa2-93b6-f6237ad37796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top normalized categories (after rules):\n",
      "category_norm\n",
      "information technology    3288\n",
      "engineering               2292\n",
      "design                     798\n",
      "finance                    670\n",
      "management                 657\n",
      "business analyst           565\n",
      "education                  388\n",
      "sales                      348\n",
      "consulting                 346\n",
      "digital media              342\n",
      "retail                     317\n",
      "marketing                  314\n",
      "hr                         305\n",
      "healthcare                 297\n",
      "banking                    292\n",
      "legal                      282\n",
      "data science               275\n",
      "agriculture                228\n",
      "operations                 197\n",
      "hospitality                152\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top raw categories still mapped to OTHER:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 4 — Category normalization (Exact map + Rule-based fallback)\n",
    "# Goal: reduce \"other\" from 6k -> <1k (ideally near 0)\n",
    "# ============================================================\n",
    "\n",
    "EXACT_MAP = {\n",
    "    # HR\n",
    "    \"human resources\": \"hr\",\n",
    "    \"hr\": \"hr\",\n",
    "\n",
    "    # Banking/Finance\n",
    "    \"accountant\": \"finance\",\n",
    "    \"finance\": \"finance\",\n",
    "    \"banking\": \"banking\",\n",
    "\n",
    "    # Marketing/media\n",
    "    \"digital media\": \"digital media\",\n",
    "    \"public relations\": \"marketing\",\n",
    "\n",
    "    # Business / PMO\n",
    "    \"business analyst\": \"business analyst\",\n",
    "    \"pmo\": \"business analyst\",\n",
    "    \"consultant\": \"consulting\",\n",
    "    \"management\": \"management\",\n",
    "    \"operations manager\": \"management\",\n",
    "\n",
    "    # Tech buckets (explicit)\n",
    "    \"information technology\": \"information technology\",\n",
    "    \"it\": \"information technology\",\n",
    "    \"data science\": \"data science\",\n",
    "    \"database\": \"information technology\",\n",
    "    \"devops\": \"information technology\",\n",
    "    \"etl developer\": \"information technology\",\n",
    "    \"sql developer\": \"information technology\",\n",
    "    \"python developer\": \"information technology\",\n",
    "    \"dotnet developer\": \"information technology\",\n",
    "    \"java developer\": \"information technology\",\n",
    "    \"react developer\": \"information technology\",\n",
    "    \"sap developer\": \"information technology\",\n",
    "    \"testing\": \"information technology\",\n",
    "    \"network security engineer\": \"information technology\",\n",
    "    \"blockchain\": \"information technology\",\n",
    "}\n",
    "\n",
    "# Rule-based mapping: checks keywords inside the category string\n",
    "RULES = [\n",
    "    # TECH / SOFTWARE / DATA\n",
    "    (r\"(data|ml|machine learning|ai|analytics|business intelligence|bi\\b|database|sql|etl|devops|cloud|aws|azure|gcp|python|java|dotnet|react|sap|testing|qa|security|network)\", \"information technology\"),\n",
    "\n",
    "    # FINANCE / ACCOUNTING\n",
    "    (r\"(finance|financial|account|accountant|audit|tax|treasury|fp&a|risk|credit|bank|banking|insurance)\", \"finance\"),\n",
    "\n",
    "    # MARKETING / MEDIA / SALES-ish comms\n",
    "    (r\"(marketing|digital|seo|sem|content|social media|brand|advertising|media|public relations|communications|crm)\", \"marketing\"),\n",
    "\n",
    "    # SALES / BIZDEV\n",
    "    (r\"(sales|business development|bd|account executive|inside sales|customer success|client success)\", \"sales\"),\n",
    "\n",
    "    # HR / PEOPLE\n",
    "    (r\"(human resources|hr\\b|recruit|talent|workforce|people)\", \"hr\"),\n",
    "\n",
    "    # HEALTHCARE / FITNESS\n",
    "    (r\"(health|healthcare|clinical|hospital|pharma|medical|patient|claims|fitness|wellness|nutrition)\", \"healthcare\"),\n",
    "\n",
    "    # EDUCATION / ACADEMIA\n",
    "    (r\"(education|teacher|teaching|faculty|professor|lecturer|school|university|college|trainer)\", \"education\"),\n",
    "\n",
    "    # LEGAL\n",
    "    (r\"(legal|law|advocate|attorney|paralegal|litigation|contract)\", \"legal\"),\n",
    "\n",
    "    # ENGINEERING (non-software)\n",
    "    (r\"(civil|mechanical|electrical|electronics|aviation|aerospace|automobile|automotive|architecture|construction|building)\", \"engineering\"),\n",
    "\n",
    "    # DESIGN / CREATIVE\n",
    "    (r\"(design|designer|ui|ux|graphic|web designing|arts|creative)\", \"design\"),\n",
    "\n",
    "    # AGRICULTURE / ENVIRONMENT\n",
    "    (r\"(agriculture|agri|farming|crop|environment|sustainability)\", \"agriculture\"),\n",
    "\n",
    "    # BPO / SUPPORT / OPERATIONS\n",
    "    (r\"(bpo|call center|customer service|support|operations|back office)\", \"operations\"),\n",
    "\n",
    "    # FOOD / HOSPITALITY\n",
    "    (r\"(food|beverage|restaurant|hospitality|chef|cooking)\", \"hospitality\"),\n",
    "\n",
    "    # APPAREL / FASHION / RETAIL\n",
    "    (r\"(apparel|fashion|retail|merchandising)\", \"retail\"),\n",
    "]\n",
    "\n",
    "def normalize_category(cat: str) -> str:\n",
    "    cat = str(cat).strip().lower()\n",
    "    if cat in EXACT_MAP:\n",
    "        return EXACT_MAP[cat]\n",
    "\n",
    "    # Apply rule-based patterns\n",
    "    for pattern, label in RULES:\n",
    "        if re.search(pattern, cat):\n",
    "            return label\n",
    "\n",
    "    # If nothing matches, keep as \"other\"\n",
    "    return \"other\"\n",
    "\n",
    "resumes[\"category_norm\"] = resumes[\"category\"].apply(normalize_category)\n",
    "\n",
    "print(\"\\nTop normalized categories (after rules):\")\n",
    "print(resumes[\"category_norm\"].value_counts().head(20))\n",
    "\n",
    "# Debug: see what is still \"other\" so we can eliminate it further\n",
    "still_other = resumes.loc[resumes[\"category_norm\"]==\"other\", \"category\"].value_counts().head(50)\n",
    "print(\"\\nTop raw categories still mapped to OTHER:\")\n",
    "print(still_other)\n",
    "\n",
    "##exact map is direct matches and rules is regex keyword matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c462aff6-5c8e-4992-bd1d-046dca01bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes[\"category_norm\"].value_counts().get(\"other\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "190e04d5-873a-470d-95c6-26e1015ec6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 5 — Matching (TF-IDF embeddings + cosine similarity)\n",
    "# ============================================================\n",
    "\n",
    "CATEGORY_FILTERS = {\n",
    "    # Finance / Banking\n",
    "    \"banking\": r\"(?:bank|banking|finance|financial|credit|risk|fraud|loan|mortgage|asset management|trading|quant|portfolio|compliance|model risk|treasury)\",\n",
    "    \"finance\": r\"(?:finance|financial|accounting|audit|tax|fp&a|portfolio|investment|trading|equity|fixed income|credit|risk|treasury|compliance)\",\n",
    "\n",
    "    # Marketing / Media\n",
    "    \"digital media\": r\"(?:marketing|seo|sem|paid media|campaign|ads|advertising|google analytics|social media|content|brand|ecommerce|crm)\",\n",
    "\n",
    "    # Tech\n",
    "    \"information technology\": r\"(?:software|cloud|aws|azure|gcp|devops|data engineer|etl|pipeline|kafka|spark|api|microservices|ci/cd|docker|kubernetes|ml|llm|nlp)\",\n",
    "\n",
    "    # HR\n",
    "    \"hr\": r\"(?:recruiting|talent|people analytics|hr analytics|compensation|benefits|workforce|employee|hrbp)\",\n",
    "\n",
    "    # Business analyst / PMO\n",
    "    \"business analyst\": r\"(?:requirements|stakeholder|business analysis|product|roadmap|user stories|agile|scrum|kpi|dashboards|reporting|analytics)\",\n",
    "\n",
    "    # Management (optional)\n",
    "    \"management\": r\"(?:operations|process improvement|strategy|planning|budget|forecast|kpi|stakeholder|program management|project management)\",\n",
    "\n",
    "    # Engineering\n",
    "    \"engineering\": r\"(?:engineering|civil|mechanical|electrical|construction|architecture|automotive|aviation|aerospace|manufacturing|plant|systems)\",\n",
    "\n",
    "    # Design\n",
    "    \"design\": r\"(?:design|designer|ui|ux|graphic|visual|product design|web design|creative)\",\n",
    "\n",
    "    # Sales\n",
    "    \"sales\": r\"(?:sales|business development|account executive|pipeline|quota|crm|customer success|client success)\",\n",
    "\n",
    "    # Consulting\n",
    "    \"consulting\": r\"(?:consultant|consulting|advisory|client|engagement|stakeholder|strategy)\",\n",
    "\n",
    "    # Healthcare\n",
    "    \"healthcare\": r\"(?:health|healthcare|clinical|hospital|pharma|medical|patient|claims|ehr|emr|hipaa)\",\n",
    "\n",
    "    # Legal\n",
    "    \"legal\": r\"(?:legal|law|advocate|attorney|paralegal|litigation|contract)\",\n",
    "\n",
    "    # Operations\n",
    "    \"operations\": r\"(?:operations|support|call center|customer service|back office|process|workflow)\",\n",
    "\n",
    "    # Hospitality\n",
    "    \"hospitality\": r\"(?:hospitality|restaurant|food|beverage|chef|kitchen|cooking|hotel)\",\n",
    "\n",
    "    # Retail\n",
    "    \"retail\": r\"(?:retail|merchandising|store|apparel|fashion|ecommerce|inventory)\",\n",
    "\n",
    "    # Education\n",
    "    \"education\": r\"(?:education|teacher|teaching|school|trainer|curriculum|student)\",\n",
    "\n",
    "    # Agriculture\n",
    "    \"agriculture\": r\"(?:agriculture|farming|crop|agri|soil|yield|sustainability)\",\n",
    "}\n",
    "\n",
    "## group resumes by bucket and then filters jobs relevant to that bucket and then run tf-idf only inside that smaller pool making it faster and more accurate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2b98e65-8bbd-4bc0-bf71-ddeebe3a511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "Category bucket: agriculture | resumes: 228 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 426 | removed: 12734\n",
      "\n",
      "===========================\n",
      "Category bucket: banking | resumes: 292 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 7630 | removed: 5530\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: business analyst | resumes: 565 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 11748 | removed: 1412\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: consulting | resumes: 346 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 8150 | removed: 5010\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: data science | resumes: 275 | jobs before filter: 13160\n",
      "No category filter found -> using global pool\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: design | resumes: 798 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 12772 | removed: 388\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: digital media | resumes: 342 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 5560 | removed: 7600\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: education | resumes: 388 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 4698 | removed: 8462\n",
      "\n",
      "===========================\n",
      "Category bucket: engineering | resumes: 2292 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 9083 | removed: 4077\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: finance | resumes: 670 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 7572 | removed: 5588\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: healthcare | resumes: 297 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 6595 | removed: 6565\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: hospitality | resumes: 152 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 559 | removed: 12601\n",
      "\n",
      "===========================\n",
      "Category bucket: hr | resumes: 305 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 8369 | removed: 4791\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: information technology | resumes: 3288 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 10064 | removed: 3096\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: legal | resumes: 282 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 6150 | removed: 7010\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: management | resumes: 657 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 8284 | removed: 4876\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: marketing | resumes: 314 | jobs before filter: 13160\n",
      "No category filter found -> using global pool\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: operations | resumes: 197 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 11278 | removed: 1882\n",
      "Capped jobs to: 5000\n",
      "\n",
      "===========================\n",
      "Category bucket: retail | resumes: 317 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 2119 | removed: 11041\n",
      "\n",
      "===========================\n",
      "Category bucket: sales | resumes: 348 | jobs before filter: 13160\n",
      "Jobs after category TEXT filter: 3967 | removed: 9193\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "top_k = 5\n",
    "MAX_JOBS_PER_CATEGORY = 5000  # set None to disable (slower)\n",
    "#### griup all reusmes in that bucket\n",
    "for cat, group in resumes.groupby(\"category_norm\"):\n",
    "    print(\"\\n===========================\")\n",
    "    print(f\"Category bucket: {cat} | resumes: {len(group)} | jobs before filter: {len(jobs)}\")\n",
    "\n",
    "    jobs_cat = jobs.copy()\n",
    "\n",
    "    # Apply category job-text filter if available\n",
    "    if cat in CATEGORY_FILTERS:\n",
    "        pattern = CATEGORY_FILTERS[cat]\n",
    "        before_cat = len(jobs_cat)\n",
    "        jobs_cat = jobs_cat[jobs_cat[\"job_text\"].str.lower().str.contains(pattern, regex=True, na=False)].copy()\n",
    "        print(f\"Jobs after category TEXT filter: {len(jobs_cat)} | removed: {before_cat - len(jobs_cat)}\")\n",
    "    else:\n",
    "        print(\"No category filter found -> using global pool\")\n",
    "\n",
    "    # Fallback if too few jobs -- so you dont end up matching against tiny pool\n",
    "    if len(jobs_cat) < 300:\n",
    "        print(\"Too few jobs after filtering -> fallback to global pool.\")\n",
    "        jobs_cat = jobs.copy()\n",
    "\n",
    "    # Optional cap for speed\n",
    "    if MAX_JOBS_PER_CATEGORY is not None and len(jobs_cat) > MAX_JOBS_PER_CATEGORY:\n",
    "        jobs_cat = jobs_cat.sample(MAX_JOBS_PER_CATEGORY, random_state=42).copy()   ### keeps run time manageable \n",
    "        print(f\"Capped jobs to: {len(jobs_cat)}\")\n",
    "\n",
    "    # TF-IDF embeddings  -- you fit tf -idf once on combined text so resumes and jobs share same vocab + vector space \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_features=60000,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([jobs_cat[\"job_text\"], group[\"text_cv\"]], ignore_index=True)\n",
    "    X = vectorizer.fit_transform(combined)\n",
    "### first part is jobs and second part is resumes \n",
    "    job_vecs = X[:len(jobs_cat)]\n",
    "    res_vecs = X[len(jobs_cat):]\n",
    "\n",
    "    # Similarity scores-- produces a matrix rows = resumes in this bucket ; cols = jobs in thi bucket; val = similarity score (0 to 1)\n",
    "    sim = cosine_similarity(res_vecs, job_vecs)\n",
    "\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(group)):\n",
    "        best = sim[i].argsort()[::-1][:top_k] ###argsort() gives job indices sorted by score ##[::-1] reverses (highest first) ##[:5] takes top 5\n",
    "        for rank, j in enumerate(best, start=1):\n",
    "            results.append({\n",
    "                \"resume_id\": int(group.loc[i, \"resume_id\"]),\n",
    "                \"resume_category_raw\": group.loc[i, \"category\"],\n",
    "                \"resume_category_norm\": cat,\n",
    "                \"rank\": rank,\n",
    "                \"score\": float(sim[i, j]),\n",
    "                \"job_id\": int(jobs_cat.iloc[j][\"job_id\"]),\n",
    "                \"job_title\": jobs_cat.iloc[j][\"job_title\"],\n",
    "                \"company_name\": jobs_cat.iloc[j].get(\"company_name\", None),\n",
    "                \"location\": jobs_cat.iloc[j].get(\"location\", None),\n",
    "                \"source\": jobs_cat.iloc[j][\"source\"],\n",
    "            })\n",
    "\n",
    "## store results  you append rows like resume id , cat. rank score, job id , job title, cmpany, loctm, source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70c5ecfc-ef6e-4a1c-85ad-f4863f052bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved matches file.\n",
      "       resume_id resume_category_raw resume_category_norm  rank     score  \\\n",
      "27630          0          accountant              finance     1  0.105080   \n",
      "27631          0          accountant              finance     2  0.098859   \n",
      "27632          0          accountant              finance     3  0.088279   \n",
      "27633          0          accountant              finance     4  0.080278   \n",
      "27634          0          accountant              finance     5  0.071238   \n",
      "27635          1          accountant              finance     1  0.150918   \n",
      "27636          1          accountant              finance     2  0.127709   \n",
      "27637          1          accountant              finance     3  0.107706   \n",
      "27638          1          accountant              finance     4  0.107021   \n",
      "27639          1          accountant              finance     5  0.104937   \n",
      "27640          2          accountant              finance     1  0.110799   \n",
      "27641          2          accountant              finance     2  0.109444   \n",
      "27642          2          accountant              finance     3  0.108967   \n",
      "27643          2          accountant              finance     4  0.107635   \n",
      "27644          2          accountant              finance     5  0.107162   \n",
      "\n",
      "       job_id                                          job_title company_name  \\\n",
      "27630    8560                          Data Scientist - Insights          NaN   \n",
      "27631   11710  Sr. to Lead Data Scientist - AML / Anti-Money ...          NaN   \n",
      "27632   14076                   Research & Instruction Librarian          NaN   \n",
      "27633    1232                Bootcamp Data Analyst Trainer (FTC)          NaN   \n",
      "27634    5437  Assistant Vice President, Anti Financial Crime...          NaN   \n",
      "27635   13525                   Division Controller - Now Hiring          NaN   \n",
      "27636    7151  Corporate Accountant I or II - Financial Accou...          NaN   \n",
      "27637    2619  Senior Accountant, Financial Analysis and Repo...          NaN   \n",
      "27638    5998                          Senior Accounting Analyst          NaN   \n",
      "27639     374                 Senior Financial Analyst - 1520658          NaN   \n",
      "27640     181         Senior Accounting Analyst (Liabilities/AP)          NaN   \n",
      "27641    1714               S12289 - Accounts Receivable Analyst          NaN   \n",
      "27642    2389                            Senior Treasury Analyst          NaN   \n",
      "27643   13160             Financial Accounting Reporting Analyst          NaN   \n",
      "27644    5681                       Real Estate Staff Accountant          NaN   \n",
      "\n",
      "      location source  \n",
      "27630      NaN    df1  \n",
      "27631      NaN    df1  \n",
      "27632      NaN    df1  \n",
      "27633      NaN    df1  \n",
      "27634      NaN    df1  \n",
      "27635      NaN    df1  \n",
      "27636      NaN    df1  \n",
      "27637      NaN    df1  \n",
      "27638      NaN    df1  \n",
      "27639      NaN    df1  \n",
      "27640      NaN    df1  \n",
      "27641      NaN    df1  \n",
      "27642      NaN    df1  \n",
      "27643      NaN    df1  \n",
      "27644      NaN    df1  \n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame(results).sort_values([\"resume_id\", \"rank\"])\n",
    "out.to_csv(r\"C:\\Users\\jhanvi.kasundra\\Downloads\\Projects New\\Data\\matches_tfidf_all.csv\", index=False)\n",
    "## save matches \n",
    "print(\"\\nSaved matches file.\")\n",
    "print(out.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b54c663-94d2-4297-88e6-477709e6d58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: matches_with_skill_gap.csv\n",
      "   resume_id  job_id  rank     score resume_category_norm  \\\n",
      "0          0    8560     1  0.105080              finance   \n",
      "1          0   11710     2  0.098859              finance   \n",
      "2          0   14076     3  0.088279              finance   \n",
      "3          0    1232     4  0.080278              finance   \n",
      "4          0    5437     5  0.071238              finance   \n",
      "5          1   13525     1  0.150918              finance   \n",
      "6          1    7151     2  0.127709              finance   \n",
      "7          1    2619     3  0.107706              finance   \n",
      "8          1    5998     4  0.107021              finance   \n",
      "9          1     374     5  0.104937              finance   \n",
      "\n",
      "                                           job_title resume_skills  \\\n",
      "0                          Data Scientist - Insights           sql   \n",
      "1  Sr. to Lead Data Scientist - AML / Anti-Money ...           sql   \n",
      "2                   Research & Instruction Librarian           sql   \n",
      "3                Bootcamp Data Analyst Trainer (FTC)           sql   \n",
      "4  Assistant Vice President, Anti Financial Crime...           sql   \n",
      "5                   Division Controller - Now Hiring                 \n",
      "6  Corporate Accountant I or II - Financial Accou...                 \n",
      "7  Senior Accountant, Financial Analysis and Repo...                 \n",
      "8                          Senior Accounting Analyst                 \n",
      "9                 Senior Financial Analyst - 1520658                 \n",
      "\n",
      "                                          job_skills  \\\n",
      "0                            python, r, sql, tableau   \n",
      "1                                             python   \n",
      "2                                                      \n",
      "3  excel, experiment, pandas, power bi, python, s...   \n",
      "4                                         r, tableau   \n",
      "5                                        forecasting   \n",
      "6                                        forecasting   \n",
      "7                                              excel   \n",
      "8                                              excel   \n",
      "9                                                      \n",
      "\n",
      "                                      missing_skills  missing_skills_count  \n",
      "0                                 python, r, tableau                     3  \n",
      "1                                             python                     1  \n",
      "2                                                                        0  \n",
      "3  excel, experiment, pandas, power bi, python, s...                     8  \n",
      "4                                         r, tableau                     2  \n",
      "5                                        forecasting                     1  \n",
      "6                                        forecasting                     1  \n",
      "7                                              excel                     1  \n",
      "8                                              excel                     1  \n",
      "9                                                                        0  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 6 — Skill Extraction + Skill Gap (adds explainability)\n",
    "# ============================================================\n",
    "\n",
    "# A starter skills list (expand anytime)\n",
    "SKILLS = [\n",
    "    \"python\",\"sql\",\"excel\",\"tableau\",\"power bi\",\"spss\",\"r\",\"sas\",\n",
    "    \"aws\",\"azure\",\"gcp\",\"snowflake\",\"databricks\",\"spark\",\"hadoop\",\"kafka\",\"airflow\",\"dbt\",\n",
    "    \"pandas\",\"numpy\",\"scikit-learn\",\"tensorflow\",\"pytorch\",\n",
    "    \"nlp\",\"bert\",\"llm\",\"prompt engineering\",\n",
    "    \"statistics\",\"regression\",\"classification\",\"time series\",\"forecasting\",\n",
    "    \"ab testing\",\"experiment\",\"etl\",\"data pipeline\",\"data modeling\",\"dimensional modeling\",\n",
    "    \"git\",\"ci/cd\",\"docker\",\"kubernetes\"\n",
    "]\n",
    "\n",
    "def extract_skills(text: str) -> set:\n",
    "    text_l = str(text).lower()\n",
    "    found = set()\n",
    "    for s in SKILLS:\n",
    "        # word boundary-ish match; works fine for most skill tokens\n",
    "        pattern = r\"\\b\" + re.escape(s.lower()) + r\"\\b\"\n",
    "        if re.search(pattern, text_l):\n",
    "            found.add(s)\n",
    "    return found\n",
    "\n",
    "# Load matches\n",
    "matches = pd.read_csv(r\"C:\\Users\\jhanvi.kasundra\\Downloads\\Projects New\\Data\\matches_tfidf_all.csv\")\n",
    "\n",
    "# Create quick lookup tables for full text\n",
    "jobs_lookup = jobs.set_index(\"job_id\")\n",
    "res_lookup = resumes.set_index(\"resume_id\")\n",
    "\n",
    "rows = []\n",
    "for _, m in matches.iterrows():\n",
    "    rid = int(m[\"resume_id\"])\n",
    "    jid = int(m[\"job_id\"])\n",
    "\n",
    "    resume_text = res_lookup.loc[rid, \"text_cv\"]\n",
    "    job_text = jobs_lookup.loc[jid, \"job_text\"]\n",
    "\n",
    "    r_sk = extract_skills(resume_text)\n",
    "    j_sk = extract_skills(job_text)\n",
    "\n",
    "    rows.append({\n",
    "        \"resume_id\": rid,\n",
    "        \"job_id\": jid,\n",
    "        \"rank\": int(m[\"rank\"]),\n",
    "        \"score\": float(m[\"score\"]),\n",
    "        \"resume_category_norm\": m[\"resume_category_norm\"],\n",
    "        \"job_title\": m[\"job_title\"],\n",
    "        \"resume_skills\": \", \".join(sorted(r_sk)),\n",
    "        \"job_skills\": \", \".join(sorted(j_sk)),\n",
    "        \"missing_skills\": \", \".join(sorted(j_sk - r_sk)),\n",
    "        \"missing_skills_count\": len(j_sk - r_sk)\n",
    "    })\n",
    "\n",
    "skill_gap_df = pd.DataFrame(rows)\n",
    "skill_gap_df.to_csv(r\"C:\\Users\\jhanvi.kasundra\\Downloads\\Projects New\\Data\\matches_with_skill_gap.csv\", index=False)\n",
    "\n",
    "print(\"Saved: matches_with_skill_gap.csv\")\n",
    "print(skill_gap_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
